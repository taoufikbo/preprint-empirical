"""Script 03 - Analyse et visualisation

Ce script effectue l'analyse statistique et gÃ©nÃ¨re les visualisations
pour valider les hypothÃ¨ses du cadre Todd-Hofstede.
"""

import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from scipy.stats import kruskal, mannwhitneyu
from itertools import combinations
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import seaborn as sns
import umap
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Configuration plot
plt.rcParams['figure.dpi'] = 200
plt.rcParams['font.size'] = 11
sns.set_style('whitegrid')


class AnalyseurSemantique:
    """Analyseur pour valider les hypothÃ¨ses Todd-Hofstede."""
    
    def __init__(self):
        self.embeddings = None
        self.metadata = None
        self.pays_list = ['France', 'USA', 'Allemagne', 'Japon']
        self.color_map = {
            'France': '#0055A4',
            'USA': '#B22234',
            'Allemagne': '#000000',
            'Japon': '#BC002D',
            'Neutral': '#808080'
        }
    
    def charger_donnees(self,
                       emb_path: str = 'embeddings/embeddings_bge_m3.npy',
                       meta_path: str = 'embeddings/metadata.csv'):
        """Charge les embeddings et mÃ©tadonnÃ©es."""
        self.embeddings = np.load(emb_path)
        self.metadata = pd.read_csv(meta_path)
        
        print(f"âœ… DonnÃ©es chargÃ©es:")
        print(f"   Embeddings: {self.embeddings.shape}")
        print(f"   MÃ©tadonnÃ©es: {len(self.metadata)} entrÃ©es")
        print(f"\nRÃ©partition par pays:")
        print(self.metadata['pays'].value_counts())
    
    def calculer_matrice_similarite(self) -> pd.DataFrame:
        """Calcule la matrice de similaritÃ© cosinus inter/intra-pays."""
        print("\n=== Calcul de la matrice de similaritÃ© ===")
        
        # Indices par pays
        indices = {p: self.metadata[self.metadata['pays'] == p].index.tolist() 
                   for p in self.pays_list}
        
        # Matrice de similaritÃ©
        sim_matrix = pd.DataFrame(index=self.pays_list, 
                                 columns=self.pays_list, 
                                 dtype=float)
        
        for p1 in self.pays_list:
            for p2 in self.pays_list:
                emb1 = self.embeddings[indices[p1]]
                emb2 = self.embeddings[indices[p2]]
                sim = cosine_similarity(emb1, emb2)
                
                if p1 == p2:
                    # Intra-pays: moyenne hors diagonale
                    np.fill_diagonal(sim, np.nan)
                    sim_matrix.loc[p1, p2] = np.nanmean(sim)
                else:
                    # Inter-pays: moyenne de toutes les similaritÃ©s
                    sim_matrix.loc[p1, p2] = sim.mean()
        
        print("\nğŸ“Š Matrice de similaritÃ© cosinus:")
        print(sim_matrix.round(3))
        
        # Sauvegarder
        Path('results').mkdir(exist_ok=True)
        sim_matrix.to_csv('results/matrice_similarite.csv')
        print("\nâœ… Matrice sauvegardÃ©e: results/matrice_similarite.csv")
        
        return sim_matrix
    
    def analyser_distance_scrum_guide(self) -> pd.DataFrame:
        """Calcule la distance de chaque pays au Scrum Guide."""
        print("\n=== Analyse distance au Scrum Guide ===")
        
        # Embedding du Scrum Guide (rÃ©fÃ©rence neutre)
        sg_idx = self.metadata[self.metadata['source'].str.contains('Scrum Guide', na=False)].index.tolist()
        
        if len(sg_idx) == 0:
            print("âš ï¸  Scrum Guide non trouvÃ© dans les mÃ©tadonnÃ©es")
            return None
        
        sg_embedding = self.embeddings[sg_idx].mean(axis=0, keepdims=True)
        
        # Calculer les distances par pays
        resultats = []
        
        for pays in self.pays_list:
            idx_pays = self.metadata[self.metadata['pays'] == pays].index.tolist()
            emb_pays = self.embeddings[idx_pays]
            
            # SimilaritÃ©s cosinus avec le Scrum Guide
            similarities = cosine_similarity(emb_pays, sg_embedding).flatten()
            
            resultats.append({
                'pays': pays,
                'similarite_moyenne': similarities.mean(),
                'similarite_std': similarities.std(),
                'n_textes': len(similarities)
            })
            
            print(f"{pays:12s} â†’ Scrum Guide : {similarities.mean():.3f} (Ïƒ={similarities.std():.3f})")
        
        df_resultats = pd.DataFrame(resultats)
        df_resultats.to_csv('results/distances_scrum_guide.csv', index=False)
        
        return df_resultats
    
    def test_statistique_significativite(self) -> dict:
        """Teste si les diffÃ©rences entre pays sont significatives."""
        print("\n=== Tests statistiques ===")
        
        # Embedding Scrum Guide
        sg_idx = self.metadata[self.metadata['source'].str.contains('Scrum Guide', na=False)].index.tolist()
        sg_embedding = self.embeddings[sg_idx].mean(axis=0, keepdims=True)
        
        # Distances au Scrum Guide par pays
        distances_par_pays = {}
        for pays in self.pays_list:
            idx_pays = self.metadata[self.metadata['pays'] == pays].index.tolist()
            emb_pays = self.embeddings[idx_pays]
            distances_par_pays[pays] = cosine_similarity(emb_pays, sg_embedding).flatten()
        
        # Test de Kruskal-Wallis (non-paramÃ©trique)
        stat, p_value = kruskal(*distances_par_pays.values())
        
        print(f"\nğŸ§  Kruskal-Wallis H-test:")
        print(f"   H = {stat:.2f}")
        print(f"   p-value = {p_value:.4f}")
        
        if p_value < 0.05:
            print("   âœ… Les distances au Scrum Guide diffÃ¨rent significativement entre pays")
        else:
            print("   âš ï¸  Pas de diffÃ©rence significative dÃ©tectÃ©e")
        
        # Tests post-hoc par paires (Mann-Whitney U)
        print("\nğŸ” Tests par paires (Mann-Whitney U):")
        print(f"{'Pays 1':<12} {'Pays 2':<12} {'U':>8} {'p-value':>10} {'Signif'}")
        print("-" * 60)
        
        resultats_paires = []
        for p1, p2 in combinations(self.pays_list, 2):
            stat, p = mannwhitneyu(distances_par_pays[p1], distances_par_pays[p2])
            sig = "âœ… *" if p < 0.05 else "  ns"
            print(f"{p1:<12} {p2:<12} {stat:8.1f} {p:10.4f} {sig}")
            
            resultats_paires.append({
                'pays1': p1,
                'pays2': p2,
                'U_statistic': stat,
                'p_value': p,
                'significatif': p < 0.05
            })
        
        df_paires = pd.DataFrame(resultats_paires)
        df_paires.to_csv('results/tests_statistiques.csv', index=False)
        
        return {
            'kruskal_H': stat,
            'kruskal_p': p_value,
            'paires': df_paires
        }
    
    def visualiser_umap(self, figsize=(14, 10)):
        """GÃ©nÃ¨re la visualisation UMAP 2D de l'espace sÃ©mantique."""
        print("\n=== GÃ©nÃ©ration visualisation UMAP ===")
        
        # RÃ©duction de dimension
        print("ğŸ”„ UMAP en cours...")
        reducer = umap.UMAP(
            n_components=2,
            metric='cosine',
            random_state=42,
            n_neighbors=10,
            min_dist=0.1
        )
        embedding_2d = reducer.fit_transform(self.embeddings)
        
        # PrÃ©parer les couleurs et markers
        colors = [self.color_map.get(self.metadata.loc[i, 'pays'], 'gray') 
                  for i in range(len(self.metadata))]
        
        marker_map = {'referentiel': 's', 'offre': 'o', 'reference': '*'}
        
        # Plot
        fig, ax = plt.subplots(figsize=figsize)
        
        for i in range(len(self.metadata)):
            pays = self.metadata.loc[i, 'pays']
            type_doc = self.metadata.loc[i, 'type'] if 'type' in self.metadata.columns else 'offre'
            marker = marker_map.get(type_doc, 'o')
            
            # Taille spÃ©ciale pour le Scrum Guide
            if 'Scrum Guide' in str(self.metadata.loc[i, 'source']):
                size = 200
                marker = '*'
                edgecolor = 'black'
                linewidth = 2
            else:
                size = 80
                edgecolor = 'white'
                linewidth = 0.5
            
            ax.scatter(
                embedding_2d[i, 0], 
                embedding_2d[i, 1],
                c=self.color_map.get(pays, 'gray'),
                marker=marker,
                s=size,
                alpha=0.7,
                edgecolors=edgecolor,
                linewidth=linewidth
            )
        
        # LÃ©gende
        patches = [mpatches.Patch(color=c, label=p) 
                   for p, c in self.color_map.items() if p in self.metadata['pays'].values]
        ax.legend(handles=patches, fontsize=12, loc='best', framealpha=0.9)
        
        ax.set_title(
            'Espace sÃ©mantique des rÃ´les agiles par pays\n(BGE-M3 + UMAP)',
            fontsize=16,
            fontweight='bold'
        )
        ax.set_xlabel('UMAP Dimension 1', fontsize=12)
        ax.set_ylabel('UMAP Dimension 2', fontsize=12)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('results/clusters_umap.png', dpi=200, bbox_inches='tight')
        print("âœ… Visualisation sauvegardÃ©e: results/clusters_umap.png")
        
        return fig, ax
    
    def generer_rapport(self, output_path: str = 'results/analyse.md'):
        """GÃ©nÃ¨re un rapport markdown avec l'interprÃ©tation."""
        print("\n=== GÃ©nÃ©ration du rapport ===")
        
        # Charger les rÃ©sultats
        sim_matrix = pd.read_csv('results/matrice_similarite.csv', index_col=0)
        distances_sg = pd.read_csv('results/distances_scrum_guide.csv')
        
        rapport = f"""# Analyse sÃ©mantique - RÃ©sultats Phase 3

Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}

## 1. Matrice de similaritÃ© inter/intra-pays

{sim_matrix.to_markdown()}

### InterprÃ©tation

- **SimilaritÃ© intra-pays**: Les valeurs sur la diagonale indiquent la cohÃ©rence sÃ©mantique au sein d'un mÃªme pays.
- **SimilaritÃ© inter-pays**: Les valeurs hors diagonale montrent la proximitÃ© entre pays.

## 2. Distance au Scrum Guide

{distances_sg.to_markdown(index=False)}

### HypothÃ¨ses prÃ©dites vs observÃ©es

| Pays | HypothÃ¨se | SimilaritÃ© prÃ©dite | SimilaritÃ© observÃ©e | Validation |
|------|-----------|---------------------|----------------------|------------|
| USA | RÃ´le conforme au Scrum Guide | 0.70+ | {distances_sg[distances_sg['pays']=='USA']['similarite_moyenne'].values[0]:.3f} | Ã€ valider |
| Allemagne | Friction procÃ©durale | 0.55-0.65 | {distances_sg[distances_sg['pays']=='Allemagne']['similarite_moyenne'].values[0]:.3f} | Ã€ valider |
| France | RÃ©absorption hiÃ©rarchique | 0.45-0.55 | {distances_sg[distances_sg['pays']=='France']['similarite_moyenne'].values[0]:.3f} | Ã€ valider |
| Japon | ProcÃ©duralisation | 0.40-0.50 | {distances_sg[distances_sg['pays']=='Japon']['similarite_moyenne'].values[0]:.3f} | Ã€ valider |

## 3. Visualisation

![Clusters UMAP](clusters_umap.png)

## 4. Conclusions provisoires

**Ã€ COMPLÃ‰TER aprÃ¨s examen des rÃ©sultats:**

- [ ] Les offres amÃ©ricaines sont-elles les plus proches du Scrum Guide ?
- [ ] Les offres franÃ§aises montrent-elles un vocabulaire hiÃ©rarchique ?
- [ ] Les offres japonaises montrent-elles un vocabulaire procÃ©dural ?
- [ ] Les diffÃ©rences sont-elles statistiquement significatives ?

## 5. Limites

- Corpus exploratoire (n={len(self.metadata)} textes)
- BGE-M3 est un modÃ¨le gÃ©nÃ©ral (pas spÃ©cialisÃ© vocabulaire agile)
- Traduction implicite par embeddings multilingues (biais possibles)
- Les offres reflÃ¨tent ce qui est *prescrit*, pas *pratiquÃ©*

## 6. Prochaines Ã©tapes

1. Analyse qualitative des textes les plus reprÃ©sentatifs par pays
2. Questionnaire auprÃ¨s des praticiens (validation terrain)
3. IntÃ©gration des rÃ©sultats dans le preprint
"""        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(rapport)
        
        print(f"âœ… Rapport sauvegardÃ©: {output_path}")
        return rapport


# ============================================================================
# SCRIPT PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    
    # Initialiser l'analyseur
    analyseur = AnalyseurSemantique()
    
    # Charger les donnÃ©es
    analyseur.charger_donnees(
        emb_path='embeddings/embeddings_bge_m3.npy',
        meta_path='embeddings/metadata.csv'
    )
    
    # Ã‰tape 3.1: Matrice de similaritÃ©
    sim_matrix = analyseur.calculer_matrice_similarite()
    
    # Ã‰tape 3.2: Distance au Scrum Guide
    distances = analyseur.analyser_distance_scrum_guide()
    
    # Ã‰tape 3.3: Tests statistiques
    tests = analyseur.test_statistique_significativite()
    
    # Ã‰tape 3.4: Visualisation UMAP
    fig, ax = analyseur.visualiser_umap()
    
    # Ã‰tape 3.5: Rapport final
    rapport = analyseur.generer_rapport()
    
    print("\n" + "="*70)
    print("ğŸ‰ PHASE 3 TERMINÃ‰E!")
    print("="*70)
    print("âœ… Analyse complÃ¨te")
    print("\nğŸ“ Fichiers gÃ©nÃ©rÃ©s dans results/:")
    print("   - matrice_similarite.csv")
    print("   - distances_scrum_guide.csv")
    print("   - tests_statistiques.csv")
    print("   - clusters_umap.png")
    print("   - analyse.md")
    print("\nğŸ“ PROCHAINES Ã‰TAPES:")
    print("1. Examiner results/analyse.md")
    print("2. Valider les hypothÃ¨ses H1-H4")
    print("3. IntÃ©grer dans le preprint")
    print("="*70)
