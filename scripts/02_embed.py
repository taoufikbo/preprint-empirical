"""Script 02 - Calcul des embeddings\n\nCe script calcule les embeddings BGE-M3 pour le corpus collect√©.\nSupporte le calcul local, via Hugging Face Inference, ou Google Colab.\n"""\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport time\nfrom typing import List, Optional\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nclass EmbeddingCalculator:\n    """Calculateur d'embeddings BGE-M3 avec plusieurs backends."""\n    \n    def __init__(self, model_name: str = 'BAAI/bge-m3'):\n        self.model_name = model_name\n        self.model = None\n        self.embeddings = None\n        self.metadata = None\n        \n    def charger_corpus(self, filepath: str = 'data/corpus.csv') -> pd.DataFrame:\n        """Charge le corpus consolid√©."""\n        df = pd.read_csv(filepath)\n        print(f"‚úÖ Corpus charg√©: {len(df)} textes")\n        print(f"\nR√©partition par pays:")\n        print(df['pays'].value_counts())\n        print(f"\nR√©partition par type:")\n        print(df['type'].value_counts())\n        return df\n    \n    def calculer_embeddings_local(self, \n                                   texts: List[str], \n                                   batch_size: int = 16,\n                                   normalize: bool = True) -> np.ndarray:\n        """Calcule les embeddings en local avec sentence-transformers.\n        \n        Args:\n            texts: Liste des textes √† encoder\n            batch_size: Taille des batchs\n            normalize: Normaliser les vecteurs (recommand√© pour cosine similarity)\n            \n        Returns:\n            Array numpy de shape (n_texts, 1024)\n        """\n        try:\n            from sentence_transformers import SentenceTransformer\n        except ImportError:\n            raise ImportError(\n                "sentence-transformers non install√©. "+\n                "Ex√©cutez: pip install sentence-transformers"\n            )\n        \n        print(f"üîÑ Chargement du mod√®le {self.model_name}...")\n        print("   (Premier t√©l√©chargement: ~2 Go, peut prendre quelques minutes)")\n        \n        self.model = SentenceTransformer(self.model_name)\n        \n        print(f"\nüßÆ Calcul des embeddings pour {len(texts)} textes...")\n        print(f"   Batch size: {batch_size}")\n        print(f"   Normalize: {normalize}")\n        \n        start_time = time.time()\n        \n        embeddings = self.model.encode(\n            texts,\n            batch_size=batch_size,\n            show_progress_bar=True,\n            normalize_embeddings=normalize,\n            convert_to_numpy=True\n        )\n        \n        elapsed = time.time() - start_time\n        print(f"\n‚úÖ Embeddings calcul√©s en {elapsed:.1f}s")\n        print(f"   Shape: {embeddings.shape}")\n        print(f"   Dimension: {embeddings.shape[1]}")\n        \n        return embeddings\n    \n    def calculer_embeddings_hf_inference(self,\n                                         texts: List[str],\n                                         endpoint_url: str,\n                                         hf_token: str,\n                                         batch_size: int = 16) -> np.ndarray:\n        """Calcule les embeddings via Hugging Face Inference Endpoint.\n        \n        Args:\n            texts: Liste des textes √† encoder\n            endpoint_url: URL de l'endpoint HF\n            hf_token: Token Hugging Face\n            batch_size: Taille des batchs\n            \n        Returns:\n            Array numpy de shape (n_texts, 1024)\n        """\n        import requests\n        from tqdm import tqdm\n        \n        def get_embeddings_batch(batch):\n            response = requests.post(\n                endpoint_url,\n                json={"inputs": batch},\n                headers={\n                    "Authorization": f"Bearer {hf_token}",\n                    "Content-Type": "application/json"\n                }\n            )\n            if response.status_code == 200:\n                return np.array(response.json()['embeddings'])\n            else:\n                raise ValueError(f"Erreur {response.status_code}: {response.text}")\n        \n        print(f"üîÑ Calcul via Hugging Face Inference Endpoint...")\n        print(f"   Batch size: {batch_size}")\n        \n        all_embeddings = []\n        for i in tqdm(range(0, len(texts), batch_size)):\n            batch = texts[i:i+batch_size]\n            emb = get_embeddings_batch(batch)\n            all_embeddings.append(emb)\n            time.sleep(0.1)  # Rate limiting\n        \n        embeddings = np.vstack(all_embeddings)\n        print(f"‚úÖ Embeddings calcul√©s: {embeddings.shape}")\n        \n        return embeddings\n    \n    def sauvegarder_embeddings(self,\n                               embeddings: np.ndarray,\n                               metadata: pd.DataFrame,\n                               emb_path: str = 'embeddings/embeddings_bge_m3.npy',\n                               meta_path: str = 'embeddings/metadata.csv'):\n        """Sauvegarde les embeddings et m√©tadonn√©es."""\n        # Cr√©er le dossier si n√©cessaire\n        Path(emb_path).parent.mkdir(parents=True, exist_ok=True)\n        \n        # Sauvegarder embeddings\n        np.save(emb_path, embeddings)\n        print(f"‚úÖ Embeddings sauvegard√©s: {emb_path}")\n        print(f"   Shape: {embeddings.shape}")\n        \n        # Sauvegarder m√©tadonn√©es\n        metadata.to_csv(meta_path, index=False)\n        print(f"‚úÖ M√©tadonn√©es sauvegard√©es: {meta_path}")\n        print(f"   Colonnes: {list(metadata.columns)}")\n    \n    def charger_embeddings(self,\n                          emb_path: str = 'embeddings/embeddings_bge_m3.npy',\n                          meta_path: str = 'embeddings/metadata.csv'):\n        """Charge les embeddings existants."""\n        self.embeddings = np.load(emb_path)\n        self.metadata = pd.read_csv(meta_path)\n        \n        print(f"‚úÖ Embeddings charg√©s: {self.embeddings.shape}")\n        print(f"‚úÖ M√©tadonn√©es charg√©es: {len(self.metadata)} entr√©es")\n        \n        return self.embeddings, self.metadata\n    \n    def verifier_embeddings(self,\n                           embeddings: np.ndarray,\n                           metadata: pd.DataFrame):\n        """V√©rifie l'int√©grit√© des embeddings."""\n        print("\n=== V√©rification des embeddings ===")\n        \n        # V√©rifier les dimensions\n        assert embeddings.shape[0] == len(metadata), \
            f"Mismatch: {embeddings.shape[0]} embeddings vs {len(metadata)} m√©tadonn√©es"\n        print(f"‚úÖ Nombre d'embeddings = nombre de m√©tadonn√©es ({embeddings.shape[0]})")\n        \n        # V√©rifier la dimension\n        assert embeddings.shape[1] == 1024, \
            f"Dimension attendue: 1024, re√ßue: {embeddings.shape[1]}"\n        print(f"‚úÖ Dimension correcte: {embeddings.shape[1]}")\n        \n        # V√©rifier les NaN\n        assert not np.isnan(embeddings).any(), "NaN d√©tect√©s dans les embeddings"\n        print(f"‚úÖ Pas de NaN d√©tect√©s")\n        \n        # V√©rifier la normalisation (si attendue)\n        norms = np.linalg.norm(embeddings, axis=1)\n        if np.allclose(norms, 1.0, atol=1e-3):\n            print(f"‚úÖ Vecteurs normalis√©s (L2 norm ‚âà 1.0)")\n        else:\n            print(f"‚ö†Ô∏è  Vecteurs non normalis√©s (L2 norm moyenne: {norms.mean():.3f})")\n        \n        print("\n‚úÖ Tous les tests pass√©s!")\n\n\n# ============================================================================\n# SCRIPT PRINCIPAL\n# ============================================================================\n\nif __name__ == "__main__":\n    \n    # Configuration\n    MODE = "local"  # Options: "local", "hf_inference", "colab"\n    \n    # Initialiser le calculateur\n    calc = EmbeddingCalculator(model_name='BAAI/bge-m3')\n    \n    # Charger le corpus\n    df = calc.charger_corpus('data/corpus.csv')\n    \n    # Extraire les textes et m√©tadonn√©es\n    texts = df['texte_brut'].tolist()\n    metadata = df[['id', 'pays', 'role', 'source', 'langue', 'type']].copy()\n    \n    # ========================================================================\n    # MODE 1: Calcul local (recommand√©)\n    # ========================================================================\n    if MODE == "local":\n        embeddings = calc.calculer_embeddings_local(\n            texts=texts,\n            batch_size=16,\n            normalize=True\n        )\n    \n    # ========================================================================\n    # MODE 2: Hugging Face Inference (si pas de GPU local)\n    # ========================================================================\n    elif MODE == "hf_inference":\n        HF_ENDPOINT = "https://YOUR-ENDPOINT.hf.space/embed"\n        HF_TOKEN = "hf_YOUR_TOKEN_HERE"\n        \n        embeddings = calc.calculer_embeddings_hf_inference(\n            texts=texts,\n            endpoint_url=HF_ENDPOINT,\n            hf_token=HF_TOKEN,\n            batch_size=16\n        )\n    \n    # ========================================================================\n    # MODE 3: Google Colab (utiliser MODE="local" dans Colab)\n    # ========================================================================\n    elif MODE == "colab":\n        print("üí° Pour Google Colab, utilisez MODE='local'")\n        print("   Colab fournit un GPU T4 gratuit qui acc√©l√®re le calcul")\n        embeddings = calc.calculer_embeddings_local(texts, batch_size=32)\n    \n    # ========================================================================\n    # V√©rification et sauvegarde\n    # ========================================================================\n    calc.verifier_embeddings(embeddings, metadata)\n    \n    calc.sauvegarder_embeddings(\n        embeddings=embeddings,\n        metadata=metadata,\n        emb_path='embeddings/embeddings_bge_m3.npy',\n        meta_path='embeddings/metadata.csv'\n    )\n    \n    print("\n" + "="*70)\n    print("üéâ PHASE 2 TERMIN√âE!")\n    print("="*70)\n    print("‚úÖ Embeddings calcul√©s et sauvegard√©s")\n    print("\nüìù PROCHAINES √âTAPES:")\n    print("1. V√©rifier les fichiers dans embeddings/")\n    print("2. Ex√©cuter scripts/03_analyze.py pour l'analyse")\n    print("="*70)\n